{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df671e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58938f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\anshr\\OneDrive\\Desktop\\IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c7bdd0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        One of the other reviewers has mentioned that ...\n",
       "1        A wonderful little production. <br /><br />The...\n",
       "2        I thought this was a wonderful way to spend ti...\n",
       "3        Basically there's a family where a little boy ...\n",
       "4        Petter Mattei's \"Love in the Time of Money\" is...\n",
       "                               ...                        \n",
       "49995    I thought this movie did a down right good job...\n",
       "49996    Bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    I am a Catholic taught in parochial elementary...\n",
       "49998    I'm going to have to disagree with the previou...\n",
       "49999    No one expects the Star Trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ded0560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  to lower  down the strinf \n",
    "df['review'][3].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47c9d5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other reviewers has mentioned that ...\n",
       "1        a wonderful little production. <br /><br />the...\n",
       "2        i thought this was a wonderful way to spend ti...\n",
       "3        basically there's a family where a little boy ...\n",
       "4        petter mattei's \"love in the time of money\" is...\n",
       "                               ...                        \n",
       "49995    i thought this movie did a down right good job...\n",
       "49996    bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    i am a catholic taught in parochial elementary...\n",
       "49998    i'm going to have to disagree with the previou...\n",
       "49999    no one expects the star trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to do  for the  whole  corpus\n",
    "\n",
    "df['review']=df['review'].str.lower()\n",
    "df['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf4caaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  to remove the  html  tags for the   purpose of the browser not for the browser \n",
    "#  for  removing the reg \n",
    "import re \n",
    "def  remove_html_tags(text):\n",
    "    pattern =re.compile('<.*?>')\n",
    "    return pattern.sub(r'',text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8df42c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50a3a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the  url  removal and  many more'\n",
    "import  re \n",
    "def url_remover(text):\n",
    "    pattern =re.compile(r\"http\\S+\")\n",
    "    return pattern.sub(r'',text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6926993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    return text.translate(str.maketrans('','',exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a475fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"My paitence is waining is this entertaining !?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a1b1086",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exclude' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14664/2774359984.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mremove_punc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14664/2039839360.py\u001b[0m in \u001b[0;36mremove_punc\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mremove_punc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaketrans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'exclude' is not defined"
     ]
    }
   ],
   "source": [
    "remove_punc(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65541bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9201b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  spelling  mistakae\n",
    "# we have to make the object of the  text blob \n",
    "\n",
    "incorrect_text=\"my plaec is the famosu\"\n",
    "txtblb=TextBlob(incorrect_text)\n",
    "txtblb.correct().string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a19722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  textblob  import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f56e484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436e008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  remove(stem):\n",
    "    new_text=[]\n",
    "    \n",
    "    for word in stem.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x=new_text[:]\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca4b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove('probably my most of the time goes into masturbating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929cd6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now  we hvave to   remove the   problem of removing the emojis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5261434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from cleantext import clean\n",
    "\n",
    "#provide string with emojis\n",
    "text = \"This sample text contains laughing emojis ðŸ˜€ ðŸ˜ƒ ðŸ˜„ ðŸ˜ ðŸ˜† ðŸ˜… ðŸ˜‚ ðŸ¤£\"\n",
    "\n",
    "clean(text, no_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e62cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f231b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_emojis(file):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb31756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_emojis(\"Love the  way you lie âœ‚ï¸âœ‚ï¸âœ‚ï¸âœ‚ï¸âœ‚ï¸âœ‚ï¸ðŸ‘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba0a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   to extract the meaning of  the emjois \n",
    "import emoji\n",
    "print(emoji.demojize('Ptyhr is ðŸ˜˜âœŒï¸âœŒï¸'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ed35fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c154706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now  we  have to  do  the  tokenisation in the    form \n",
    "# we   have  shortcoming in  the   the  every librrary \n",
    "# split\n",
    "#nltk\n",
    "#splace \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32fb475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# problems in the tokenization \n",
    "# we do always need to  \n",
    "#  i am new to new deli   treat new and new delhi different \n",
    "\n",
    "\n",
    "# prefix  $20--> 20 $\n",
    "#suffix 20km 20  km  differnt \n",
    "#mid  way suffix =----> let's let us \n",
    "# U.S.A DO NOT  SPLIT IT INTO U S A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b782b081",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1='I am going to  delhi'\n",
    "sent1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1972df9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2='I am  doing work. please  can we  meet tommorow'\n",
    "sent2.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d450f704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1a908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1='I am gonig to delhi'\n",
    "word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b7156",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_5='I have Ph.d in A.I'\n",
    "s_6='We are here to help! mail us at ansh@22gmail.com' # not to  be sepeaatted in the email \n",
    "s_7=' I have $20 in the 20km walk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89c5b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize(s_5)  #  done  correcr aboutt the infix value  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713aa3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize(s_6) # not   performd well on the mail id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818ef777",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize(s_7) # failed in the suffic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd52009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099c4aab",
   "metadata": {},
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14896f8",
   "metadata": {},
   "source": [
    "# we are  learning the  stemming and the lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b792128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mother # motherland\n",
    "#see # saw\n",
    "# walking \n",
    "# walks\n",
    "#walked \n",
    "# must treat all the things same , nhi  toh not  good  engine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e5b77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are  doing the  stemming  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c02912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter  import PorterStemmer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1497f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps =PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3a9402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(ok):\n",
    "    return \" \".join([ps.stem(word) for word in  ok.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c93086",
   "metadata": {},
   "outputs": [],
   "source": [
    "ok='men walks by walking '\n",
    "stem(ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ef6753",
   "metadata": {},
   "outputs": [],
   "source": [
    "pk='motherland mother'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839c6a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem(pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94be2b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a10716a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451d8058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
